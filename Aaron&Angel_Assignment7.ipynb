{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelCasta34/Assignment-7-Neural-Networks/blob/main/Aaron%26Angel_Assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGA9Fick4B3a"
      },
      "source": [
        "# Initialization, utilities (no TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUIdICI1s_b"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import argparse\n",
        "import PIL\n",
        "import random"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yu9m7Fp2Igo"
      },
      "source": [
        "def to_list(img):\n",
        "    return list(map(int, img.view((28*28,)).tolist()))\n",
        "\n",
        "SCALE_OFF = 0\n",
        "SCALE_RANGE = 1\n",
        "SCALE_01 = 2\n",
        "\n",
        "\n",
        "def show_image(tens, imgname=None, scale=SCALE_01):\n",
        "    \"\"\"\n",
        "    Show an image contained in a tensor. The tensor will be reshaped properly, as long as it has the required 28*28 = 784 entries.\n",
        "\n",
        "    If imgname is provided, the image will be saved to a file, otherwise it will be stored in a temporary file and displayed on screen.\n",
        "\n",
        "    The parameter scale can be used to perform one of three scaling operations:\n",
        "        SCALE_OFF: No scaling is performed, the data is expected to use values between 0 and 255\n",
        "        SCALE_RANGE: The data will be rescaled from whichever scale it has to be between 0 and 255. This is useful for data in an unknown/arbitrary range. The lowest value present in the data will be\n",
        "        converted to 0, the highest to 255, and all intermediate values will be assigned using linear interpolation\n",
        "        SCALE_01: The data will be rescaled from a range between 0 and 1 to the range between 0 and 255. This can be useful if you normalize your data into that range.\n",
        "    \"\"\"\n",
        "    r = tens.max() - tens.min()\n",
        "    img = PIL.Image.new(\"L\", (28,28))\n",
        "    scaled = tens\n",
        "    if scale == SCALE_RANGE:\n",
        "        scaled = (tens - tens.min())*255/r\n",
        "    elif scale == SCALE_01:\n",
        "        scaled = tens*255\n",
        "    img.putdata(to_list(scaled))\n",
        "    if imgname is None:\n",
        "        img.show()\n",
        "    else:\n",
        "        img.save(imgname)\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzidJ5p_3rD9"
      },
      "source": [
        "# Classification (5 TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "386jsZ5k1vX2"
      },
      "source": [
        "# Used for both tasks\n",
        "loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "# TODO 1: Choose a digit\n",
        "digit = 2\n",
        "\n",
        "# TODO 2: Change number of training iterations for classifier\n",
        "n0 = 20"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkMT2Ian4Y62"
      },
      "source": [
        "# TODO 3\n",
        "# Change Network architecture of the discriminator/classifier network. It should have 784 inputs and 1 output (0 = fake, 1 = real)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na_-h3hb4gFr"
      },
      "source": [
        "# TODO 4\n",
        "# Implement training loop for the classifier:\n",
        "# for i in range(n0):\n",
        "#     zero gradients\n",
        "#     calculate predictions for given x\n",
        "#     calculate loss, comparing the predictions with the given y\n",
        "#     calculate the gradient (loss.backward())\n",
        "#     print i and the loss\n",
        "#     perform an optimizer step\n",
        "def train_classifier(opt, model, x, y):\n",
        "    model.train()\n",
        "    for i in range(1, n0+1):\n",
        "        opt.zero_grad()\n",
        "        preds = model(x)                 # (N,1)\n",
        "        loss  = loss_fn(preds, y)        # BCE with target y\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if i == 1 or i % max(1, n0//5) == 0:\n",
        "            print(f\"[C] Epoch {i}/{n0}  loss={loss.item():.4f}\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFhul0ET4i9p"
      },
      "source": [
        "# TODO 5\n",
        "# Instantiate the network and the optimizer\n",
        "# call train_classifier with the training set\n",
        "# Calculate metrics on the validation set\n",
        "# Example:\n",
        "#      y_pred = net(x_validation[labels_validation == 3]) calculates all predictions for all images we know to be 3s\n",
        "#      (y_pred > 0.5) is a tensor that tells you if a given image was classified as your chosen digit (True) or not (False)\n",
        "#      You can convert this tensor to 0s and 1s by calling .float()\n",
        "#      (y_pred > 0.5).sum() will tell you how many of these predictions were true\n",
        "# You are supposed to calculate:\n",
        "#     For each digit from 0 to 9, which number percentage of images that were of that digit were predicted as your chosen digit\n",
        "#     The percentage of digits that were classified correctly (i.e. that were your digit and predicted as such, or were another digit and not predicted as your digit)\n",
        "#     This last value (accuracy) should be over 90% (preferably over 98%; precision and recall may be lower than that, 90-93% would be decent values)\n",
        "#     Precision (which percentage of images identified as your chosen digit was actually that digit: TP/(TP+FP))\n",
        "#     Recall (which percentage of your chosen digit was identified as such: TP/(TP+FN))\n",
        "def classify(x_train, y_train, x_validation, labels_validation):\n",
        "    # 1) instantiate & train\n",
        "    model = Discriminator()\n",
        "    opt   = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "    train_classifier(opt, model, x_train, y_train)\n",
        "\n",
        "    # 2) get predictions on validation set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = model(x_validation)       # shape (V,1)\n",
        "        preds = (probs > 0.5).float().squeeze()\n",
        "        # now preds is 1D: (V,)\n",
        "\n",
        "    # 3) ground truth for “is it our digit?”\n",
        "    y_val = (labels_validation == digit).float().squeeze()\n",
        "    # also 1D: (V,)\n",
        "\n",
        "    # 4) overall confusion\n",
        "    TP = int(((preds==1) & (y_val==1)).sum())\n",
        "    FN = int(((preds==0) & (y_val==1)).sum())\n",
        "    FP = int(((preds==1) & (y_val==0)).sum())\n",
        "    TN = int(((preds==0) & (y_val==0)).sum())\n",
        "\n",
        "    # 5) per‐digit false positives / true negatives\n",
        "    fp, tn = {}, {}\n",
        "    for d in range(10):\n",
        "        mask   = (labels_validation == d)        # 1D boolean mask\n",
        "        fp[d]  = int(((preds[mask]==1) & (labels_validation[mask]!=digit)).sum())\n",
        "        tn[d]  = int(((preds[mask]==0) & (labels_validation[mask]!=digit)).sum())\n",
        "\n",
        "    # 6) save up to 5 misclassified examples\n",
        "    saved = 0\n",
        "    for i in range(len(y_val)):\n",
        "        if preds[i] != y_val[i] and saved < 5:\n",
        "            show_image(\n",
        "                x_validation[i],\n",
        "                f\"mis_val_{i}.png\",\n",
        "                scale=SCALE_01\n",
        "            )\n",
        "            saved += 1\n",
        "\n",
        "    # 7) compute metrics\n",
        "    total     = TP + TN + FP + FN\n",
        "    accuracy  = (TP + TN) / total\n",
        "    precision = TP / (TP + FP) if TP+FP else 0.0\n",
        "    recall    = TP / (TP + FN) if TP+FN else 0.0\n",
        "\n",
        "    # 8) print results\n",
        "    print(f\"\\n=== Results for digit {digit} ===\")\n",
        "    print(f\"TP={TP}  FN={FN}  FP={FP}  TN={TN}\")\n",
        "    print(f\"Accuracy:  {accuracy*100:5.2f}%\")\n",
        "    print(f\"Precision: {precision*100:5.2f}%\")\n",
        "    print(f\"Recall:    {recall*100:5.2f}%\")\n",
        "    print(\"FP per digit:\", fp)\n",
        "    print(\"TN per digit:\", tn)\n",
        "\n",
        "    # 9) most‐confused other digit\n",
        "    other_fp = {d:cnt for d,cnt in fp.items() if d != digit}\n",
        "    if other_fp:\n",
        "        most = max(other_fp, key=other_fp.get)\n",
        "        print(f\"Most often confused with digit {most} ({other_fp[most]} times)\")\n",
        "    else:\n",
        "        print(\"No other digits confused with your choice.\")\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt4nh87Z4pQM"
      },
      "source": [
        "# GAN (5 TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpzYjdRH7J8u"
      },
      "source": [
        "# TODO 6: Change number of total training iterations for GAN, for the discriminator and for the generator\n",
        "n = 10\n",
        "n1 = 10\n",
        "n2 = 10"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZsKuRXK4uS2"
      },
      "source": [
        "# TODO 7\n",
        "# Change Network architecture of the generator network. It should have 100 inputs (will be random numbers) and 784 outputs (one for each pixel, each between 0 and 1)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(100, 256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(256, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 100)\n",
        "        return self.net(x)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r28Lozz45AoO"
      },
      "source": [
        "# TODO 8\n",
        "# Implement training loop for the discriminator, given real and fake data:\n",
        "# for i in range(n1):\n",
        "#     zero gradients\n",
        "#     calculate predictions for the x known as real\n",
        "#     calculate loss, comparing the predictions with a tensor consisting of 1s (we want all of these samples to be classified as real)\n",
        "#     calculate the gradient (loss_true.backward())\n",
        "#     calculate predictions for the x known as fake\n",
        "#     calculate loss, comparing the predictions with a tensor consisting of 0s (we want all of these samples to be classified as fake)\n",
        "#     calculate the gradient (loss_false.backward())\n",
        "#     print i and both of the loss values\n",
        "#     perform an optimizer step\n",
        "def train_discriminator(opt, discriminator, x_true, x_false):\n",
        "    discriminator.train()\n",
        "    for i in range(1, n1+1):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # real → label=1\n",
        "        pred_t = discriminator(x_true)\n",
        "        loss_t = loss_fn(pred_t, torch.ones_like(pred_t))\n",
        "        loss_t.backward()\n",
        "\n",
        "        # fake → label=0\n",
        "        pred_f = discriminator(x_false.detach())\n",
        "        loss_f = loss_fn(pred_f, torch.zeros_like(pred_f))\n",
        "        loss_f.backward()\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        if i == 1 or i == n1:\n",
        "            print(f\"[D] Epoch {i}/{n1}  loss_real={loss_t.item():.4f}  loss_fake={loss_f.item():.4f}\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeN1dXqe5Ct4"
      },
      "source": [
        "# TODO 9\n",
        "# Implement training loop for the generator:\n",
        "# for i in range(n2):\n",
        "#     zero gradients\n",
        "#     generate some random inputs\n",
        "#     calculate generated images by passing these inputs to the generator\n",
        "#     pass the generated images to the discriminator to predict if they are true or fake\n",
        "#     calculate the loss, comparing the predictions with a tensor of 1s (the *generator* wants the discriminator to classify its images as real)\n",
        "#     calculate the gradient (loss.backward())\n",
        "#     print i and the loss\n",
        "#     perform an optimization step\n",
        "def train_generator(opt, generator, discriminator):\n",
        "    generator.train()\n",
        "    for i in range(1, n2+1):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # sample noise & produce fakes\n",
        "        z      = torch.randn(100, 100)\n",
        "        x_fake = generator(z)\n",
        "\n",
        "        # want discriminator(x_fake) → 1\n",
        "        pred   = discriminator(x_fake)\n",
        "        loss_g = loss_fn(pred, torch.ones_like(pred))\n",
        "        loss_g.backward()\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        if i == 1 or i == n2:\n",
        "            print(f\"[G] Epoch {i}/{n2}  loss={loss_g.item():.4f}\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BthTT_985tYS"
      },
      "source": [
        "# TODO 10\n",
        "# Implement GAN training loop:\n",
        "# Generate some random images (with torch.rand) as an initial collection of fakes\n",
        "# Instantiate the two networks and two optimizers (one for each network!)\n",
        "# for i in range(n):\n",
        "#    call train_discriminator with the given real images and the collection of fake images\n",
        "#    call train_generator\n",
        "#    generate some images with the current generator, and add a random selection of old fake images (e.g. 100 random old ones, and 100new ones = 200 in total)\n",
        "#    this will be your new collection of fake images\n",
        "#    save some of the current fake images to a file (use a filename like \"sample_%d_%d.png\"%(i,j) so you have some samples from each iteration so you can see if the network improves)\n",
        "# If you read the todos above, your training code will print the loss in each iteration. The loss for the discriminator and the generator should decrease each time their respective training functions are called\n",
        "# The images should start to look like numbers after just a few (could be after 1 or 2 already, or 3-10) iterations of *this* loop\n",
        "def gan(x_real):\n",
        "    # a) instantiate\n",
        "    G = Generator()\n",
        "    D = Discriminator()\n",
        "    opt_g = torch.optim.Adam(G.parameters(), lr=1e-3)\n",
        "    opt_d = torch.optim.Adam(D.parameters(), lr=1e-3)\n",
        "\n",
        "    # b) initial fake‐pool of 200\n",
        "    pool_size  = 200\n",
        "    keep_old   = 100\n",
        "    keep_new   = 100\n",
        "    x_false    = torch.rand(pool_size, 28*28)\n",
        "\n",
        "    # c) outer rounds\n",
        "    for r in range(1, n+1):\n",
        "        print(f\"\\n=== GAN Round {r}/{n} ===\")\n",
        "\n",
        "        # 1) train D on current real & fake\n",
        "        train_discriminator(opt_d, D, x_real, x_false)\n",
        "\n",
        "        # 2) train G against this D\n",
        "        train_generator(opt_g, G, D)\n",
        "\n",
        "        # 3) produce new fakes\n",
        "        with torch.no_grad():\n",
        "            z_new     = torch.randn(keep_new, 100)\n",
        "            new_fakes = G(z_new).detach()\n",
        "\n",
        "        # 4) mix in some old & new\n",
        "        perm    = torch.randperm(pool_size)\n",
        "        old_sel = x_false[perm[:keep_old]]\n",
        "        x_false = torch.cat([old_sel, new_fakes], dim=0)\n",
        "\n",
        "        # 5) save a few samples\n",
        "        for j in range(5):\n",
        "            show_image(\n",
        "                x_false[j],\n",
        "                f\"sample_{r}_{j}.png\",\n",
        "                scale=SCALE_01\n",
        "            )\n",
        "\n",
        "    return G, D"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXDLr4qX5QDV"
      },
      "source": [
        "# Main (no TODOs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw5xvVZI2UN_"
      },
      "source": [
        "def main(rungan):\n",
        "    \"\"\"\n",
        "    You do not have to change this function!\n",
        "\n",
        "    It will:\n",
        "        automatically download the data set if it doesn't exist yet\n",
        "        make sure all tensor shapes are correct\n",
        "        normalize the images (all pixels between 0 and 1)\n",
        "        provide labels for the classification task (0 for all images that are not your digit, 1 for the ones that are)\n",
        "        extract the images of your chosen digit for the GAN\n",
        "    \"\"\"\n",
        "    train = torchvision.datasets.MNIST(\".\", download=True)\n",
        "    x_train = train.data.float().view(-1,28*28)/255.0\n",
        "    labels_train = train.targets\n",
        "    y_train = (labels_train == digit).float().view(-1,1)\n",
        "\n",
        "    validation = torchvision.datasets.MNIST(\".\", train=False)\n",
        "    x_validation = validation.data.float().view(-1,28*28)/255.0\n",
        "    labels_validation = validation.targets\n",
        "\n",
        "    if rungan:\n",
        "        gan(x_train[labels_train == digit])\n",
        "    else:\n",
        "        classify(x_train, y_train, x_validation, labels_validation)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7yHoNrZ5Svz"
      },
      "source": [
        "# Test call (TODO: TEST)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQm0AL2X2tzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d28e87a-dda3-427f-8ca6-89836344ca1f"
      },
      "source": [
        "# NOTE: This will not work until you have done TODO 1 above!\n",
        "# If you have not done TODO 1 yet, you will get: AttributeError: 'bool' object has no attribute 'float'\n",
        "GAN = True\n",
        "main(GAN)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== GAN Round 1/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.6238  loss_fake=0.8054\n",
            "[D] Epoch 10/10  loss_real=0.0674  loss_fake=0.0035\n",
            "[G] Epoch 1/10  loss=5.9887\n",
            "[G] Epoch 10/10  loss=2.5447\n",
            "\n",
            "=== GAN Round 2/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.0482  loss_fake=0.0731\n",
            "[D] Epoch 10/10  loss_real=0.0123  loss_fake=0.0008\n",
            "[G] Epoch 1/10  loss=7.4871\n",
            "[G] Epoch 10/10  loss=0.9545\n",
            "\n",
            "=== GAN Round 3/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.0113  loss_fake=0.6446\n",
            "[D] Epoch 10/10  loss_real=0.1595  loss_fake=0.0001\n",
            "[G] Epoch 1/10  loss=11.0011\n",
            "[G] Epoch 10/10  loss=3.2160\n",
            "\n",
            "=== GAN Round 4/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.1630  loss_fake=0.1140\n",
            "[D] Epoch 10/10  loss_real=0.0961  loss_fake=0.0516\n",
            "[G] Epoch 1/10  loss=3.8711\n",
            "[G] Epoch 10/10  loss=0.3821\n",
            "\n",
            "=== GAN Round 5/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.0843  loss_fake=1.2817\n",
            "[D] Epoch 10/10  loss_real=0.2473  loss_fake=0.0379\n",
            "[G] Epoch 1/10  loss=2.7481\n",
            "[G] Epoch 10/10  loss=0.6991\n",
            "\n",
            "=== GAN Round 6/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.1486  loss_fake=0.5722\n",
            "[D] Epoch 10/10  loss_real=0.2817  loss_fake=0.0157\n",
            "[G] Epoch 1/10  loss=3.4526\n",
            "[G] Epoch 10/10  loss=1.1213\n",
            "\n",
            "=== GAN Round 7/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.2241  loss_fake=0.3044\n",
            "[D] Epoch 10/10  loss_real=0.2165  loss_fake=0.0556\n",
            "[G] Epoch 1/10  loss=2.1376\n",
            "[G] Epoch 10/10  loss=0.1103\n",
            "\n",
            "=== GAN Round 8/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.1824  loss_fake=1.3961\n",
            "[D] Epoch 10/10  loss_real=0.4159  loss_fake=0.0998\n",
            "[G] Epoch 1/10  loss=1.1912\n",
            "[G] Epoch 10/10  loss=0.0270\n",
            "\n",
            "=== GAN Round 9/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.2750  loss_fake=2.1640\n",
            "[D] Epoch 10/10  loss_real=0.8683  loss_fake=0.0267\n",
            "[G] Epoch 1/10  loss=2.7160\n",
            "[G] Epoch 10/10  loss=0.1312\n",
            "\n",
            "=== GAN Round 10/10 ===\n",
            "[D] Epoch 1/10  loss_real=0.6702  loss_fake=1.3154\n",
            "[D] Epoch 10/10  loss_real=0.4789  loss_fake=0.0384\n",
            "[G] Epoch 1/10  loss=2.6620\n",
            "[G] Epoch 10/10  loss=0.0914\n"
          ]
        }
      ]
    }
  ]
}